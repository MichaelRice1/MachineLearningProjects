# NBA Game and Player Data Scraping & Prediction Models
This project involves scraping NBA game and player data from every season starting from 1999-00, building and training models to predict game outcomes and player statlines. The goal is to gain valuable experience working with sports data, machine learning, and model evaluation in an area of personal interest.


# Project Overview
The main components of this project include:

Data Scraping: Collecting NBA game and player data from various sources, covering all seasons since 1999-00.
Data Preprocessing: Cleaning and preparing the data for analysis and model training.
Model Development:
Predicting game outcomes (win/loss) based on game data.
Predicting individual player statlines (points, rebounds, assists) based on historical performance and game context.
Model Evaluation: Assessing the models' performance and tuning them for better accuracy.
Exploration & Insights: Gaining a deeper understanding of NBA statistics and trends, as well as improving personal expertise in machine learning.


# Project Goals
Data Acquisition: Automate the process of scraping historical NBA data to build a comprehensive dataset.
Feature Engineering: Create meaningful features from raw game data (e.g., team strength, player performance, situational factors).

Modeling: Train machine learning models (e.g., linear regression, decision trees, neural networks) to predict:
Game outcomes (win/loss) / Player statlines (points, rebounds, assists) for upcoming games.

Experimentation & Learning: Explore different machine learning algorithms, hyperparameter tuning, and model evaluation techniques.


# Technologies Used
Python: Core programming language used for data collection, cleaning, and modeling.
BeautifulSoup: Web scraping tools to gather game and player data from websites.
Pandas & NumPy: Data manipulation libraries for preprocessing and feature engineering.
Scikit-learn & XGBoost: Machine learning libraries for building and evaluating predictive models.
PyTorch: For experimenting with deep learning models.
Matplotlib: Visualization tools to analyze trends and present findings.
Git: Version control for project collaboration and tracking progress.


# Project Structure

data: all the necessary components for scraping and processing the data are in this folder
ml: all code for anything ML related, for use after data processing
